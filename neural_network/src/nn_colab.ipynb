{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "z6yWAfcwYE2q",
    "outputId": "14cbd937-837d-4939-86c1-c5bf124ceb76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import time\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "\n",
    "from minibatch import *\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU') \n",
    "for physical_device in physical_devices: \n",
    "    tf.config.experimental.set_memory_growth(physical_device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/sweet/2-coursework/725bmes/eeg_deeplearning/neural_network/src\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_RUNNING_PAIRWISE = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FQvSz7XE2XRd"
   },
   "source": [
    "# Define sliding window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uQhM362cYE4a"
   },
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import as_strided\n",
    "\n",
    "def sliding_window(a, w = 4, o = 2, copy = False):\n",
    "    sh = (a.size - w + 1, w)\n",
    "    st = a.strides * 2\n",
    "    view = np.lib.stride_tricks.as_strided(a, strides = st, shape = sh)[0::o]\n",
    "    if copy:\n",
    "        return view.copy()\n",
    "    else:\n",
    "        return view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "UC-WtEkwGLU0",
    "outputId": "0df1bb0b-bfb3-45d1-9f08-852bfd96c980"
   },
   "outputs": [],
   "source": [
    "def genAllDat(db, b, targetClas, nClas=7, nTrials=200, nWin=1, S=16, nX=9, nY=9):\n",
    "    \n",
    "    inputs = np.zeros((nWin*nTrials*nClas, S, nX, nY))\n",
    "    targets = np.zeros(nWin*nTrials*nClas, dtype=int)\n",
    "    wins = np.zeros(nWin*nTrials*nClas, dtype=int)\n",
    "\n",
    "    seq_perms = create_rand_seq_permutations(db)\n",
    "    k = 0\n",
    "    for trial in range(0,nTrials):\n",
    "        for clas in targetClas:\n",
    "            perm = seq_perms[clas][trial]\n",
    "            tmp = db[clas][perm]\n",
    "\n",
    "            for win in range(0,nWin):\n",
    "                inputs[k] = tmp[b[win,:]]\n",
    "                targets[k] = clas\n",
    "                wins[k] = win\n",
    "                k=k+1\n",
    "    return inputs, targets, wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDkzN3F42XQ4"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NpY-PqwsYE3j",
    "outputId": "405bb5e8-0091-445b-c30f-bbcccaffc8c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ME database in 0.613691 s\n"
     ]
    }
   ],
   "source": [
    "db_dir = \"/home/sweet/2-coursework/725bmes/eeg_deeplearning/neural_network/src\"\n",
    "ME_db_fname = \"mesh_NoArt_ME_db_128.pickle\"\n",
    "ME_db = {}\n",
    "\n",
    "t1 = time.time()\n",
    "with open(db_dir + \"/\" + ME_db_fname, \"rb\") as f:\n",
    "    ME_db_2Dmesh = pickle.load(f)\n",
    "print(\"Loaded ME database in %f s\" % (time.time()-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create folder for model's checkpoints\n",
    "pwd = os.getcwd()\n",
    "ckt_pt_dir = pwd + \"/check_points\"\n",
    "try:\n",
    "    if not os.path.isdir(ckt_pt_dir):\n",
    "        os.mkdir(ckt_pt_dir)\n",
    "except OSError as error:\n",
    "    print(\"Cannot create directory. Exiting...\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R8uOYTbs2XRP"
   },
   "source": [
    "# Define Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cJsAjLilYE4P"
   },
   "outputs": [],
   "source": [
    "S = 8    # S = number of images\n",
    "K = 7    # K = number of classes\n",
    "last_fc = 64\n",
    "dropout_rate = 0.5\n",
    "opt = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "lossfn = 'categorical_crossentropy'\n",
    "metric = ['acurracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "piU_PBVyNl7b"
   },
   "outputs": [],
   "source": [
    "def get_compiled_casc_model(S, K=8, last_fc=64, dropout_rate=0.5, \n",
    "                            activation_last='softmax', opt=keras.optimizers.Adam(learning_rate=1e-4), \n",
    "                            loss='categorical_crossentropy'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Input(shape=(S, 9, 9, 1)))\n",
    "    model.add(layers.TimeDistributed(layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu')))\n",
    "    model.add(layers.TimeDistributed(layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')))\n",
    "    model.add(layers.TimeDistributed(layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu')))\n",
    "    model.add(layers.TimeDistributed(layers.Flatten()))\n",
    "    model.add(layers.TimeDistributed(layers.Dense(1024, activation='relu')))\n",
    "    model.add(layers.TimeDistributed(layers.Dropout(dropout_rate)))\n",
    "    model.add(layers.LSTM(S, return_sequences=True))\n",
    "    model.add(layers.LSTM(S))\n",
    "    model.add(layers.Dense(last_fc, activation='relu'))\n",
    "    model.add(layers.Dropout(dropout_rate))\n",
    "    model.add(layers.Dense(K, activation=activation_last))\n",
    "    model.compile(loss=loss, optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(X, Y, batch_size=64):\n",
    "    i = 0\n",
    "    while True:\n",
    "        yield X[i:i+batch_size], Y[i:i+batch_size]\n",
    "        i = i + batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(749, 257, 9, 9)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes = [1,5]\n",
    "nClas = len(ME_db_2Dmesh)\n",
    "nTrials = ME_db_2Dmesh[1].shape[0]\n",
    "nFrames = ME_db_2Dmesh[1].shape[1]\n",
    "nX = ME_db_2Dmesh[1].shape[2]\n",
    "nY = ME_db_2Dmesh[1].shape[3]\n",
    "display(ME_db_2Dmesh[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_epochs = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "P95wQipBGxDR",
    "outputId": "a53e6f44-8e9f-48e0-cae6-343b3ad33f40",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if IS_RUNNING_PAIRWISE:\n",
    "    accuracy_pairwise = np.zeros((7,7))\n",
    "    for c1 in range(1,7):\n",
    "        for c2 in range(c1+1,8):\n",
    "            classes = [c1, c2]\n",
    "            print('Training on class', classes)\n",
    "            a = np.arange(nFrames)\n",
    "            b = sliding_window(a, S, S//2)\n",
    "\n",
    "            nWin = b.shape[0]\n",
    "            inputs, targets, wins = genAllDat(ME_db_2Dmesh, b, classes, len(classes), nTrials, nWin, S, nX, nY)\n",
    "            # shuffle the dataset\n",
    "            inputs, targets = shuffle(inputs, targets)\n",
    "            inputs = np.expand_dims(inputs, axis=-1)\n",
    "\n",
    "            where_are_NaNs = np.isnan(inputs)\n",
    "            inputs[where_are_NaNs] = 0\n",
    "\n",
    "            # restructure to go up starting from 1\n",
    "            j = 1\n",
    "            for i in classes:\n",
    "                targets[:] = [x if x != i else j for x in targets]\n",
    "                j = j+1\n",
    "\n",
    "            # split into training and testing set\n",
    "            X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.2)\n",
    "\n",
    "            y_train = to_categorical(y_train-1)\n",
    "            y_test = to_categorical(y_test-1)\n",
    "\n",
    "            model = get_compiled_casc_model(S, K=2)\n",
    "            t1 = time.time()\n",
    "            model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size, verbose=1)\n",
    "            print('Training on class', classes, ' finished in ', str(time.time() - t1), 's')\n",
    "\n",
    "            print('Evaluate on class', classes)\n",
    "\n",
    "            # evaluate model\n",
    "            _, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "\n",
    "            accuracy_pairwise[c1-1,c2-1] = accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 601
    },
    "colab_type": "code",
    "id": "-Cs1QTdRGXPI",
    "outputId": "8ba89c29-4386-4000-e262-322ea9f5c1db"
   },
   "outputs": [],
   "source": [
    "if IS_RUNNING_PAIRWISE:\n",
    "    accuracy_pairwise= accuracy_pairwise+np.transpose(accuracy_pairwise)\n",
    "\n",
    "    plt.figure(figsize = (7,7))\n",
    "    plt.imshow(accuracy_pairwise, cmap='hot', interpolation='nearest')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 598
    },
    "colab_type": "code",
    "id": "wbxRTu1uLMPE",
    "outputId": "ebc83359-dffd-41ea-8e62-d317ab76916e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on class [1, 2, 3, 4, 5, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "classes = [1, 2, 3, 4, 5, 6, 7]\n",
    "n_epochs = 30\n",
    "print('Training on class', classes)\n",
    "a = np.arange(nFrames)\n",
    "b = sliding_window(a, S, S//2)\n",
    "\n",
    "nWin = b.shape[0]\n",
    "inputs, targets, wins = genAllDat(ME_db_2Dmesh, b, classes, len(classes), nTrials, nWin, S, nX, nY)\n",
    "# shuffle the dataset\n",
    "inputs, targets = shuffle(inputs, targets)\n",
    "inputs = np.expand_dims(inputs, axis=-1)\n",
    "\n",
    "where_are_NaNs = np.isnan(inputs)\n",
    "inputs[where_are_NaNs] = 0\n",
    "\n",
    "# restructure to go up starting from 1\n",
    "j = 1\n",
    "for i in classes:\n",
    "    targets[:] = [x if x != i else j for x in targets]\n",
    "    j = j+1\n",
    "\n",
    "# split into training and testing set\n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, targets, test_size=0.2)\n",
    "\n",
    "y_train = to_categorical(y_train-1)\n",
    "y_test = to_categorical(y_test-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 8)\n",
      "Epoch 1/30\n",
      "3304/3304 [==============================] - 73s 22ms/step - loss: 1.9357 - accuracy: 0.1620 - val_loss: 1.9068 - val_accuracy: 0.1948\n",
      "Epoch 2/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 1.8715 - accuracy: 0.2169 - val_loss: 1.8190 - val_accuracy: 0.2581\n",
      "Epoch 3/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 1.7491 - accuracy: 0.2982 - val_loss: 1.6819 - val_accuracy: 0.3360\n",
      "Epoch 4/30\n",
      "3304/3304 [==============================] - 73s 22ms/step - loss: 1.5650 - accuracy: 0.3920 - val_loss: 1.5438 - val_accuracy: 0.4016\n",
      "Epoch 5/30\n",
      "3304/3304 [==============================] - 73s 22ms/step - loss: 1.3551 - accuracy: 0.4871 - val_loss: 1.4012 - val_accuracy: 0.4636\n",
      "Epoch 6/30\n",
      "3304/3304 [==============================] - 71s 22ms/step - loss: 1.1455 - accuracy: 0.5768 - val_loss: 1.2760 - val_accuracy: 0.5274\n",
      "Epoch 7/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.9525 - accuracy: 0.6544 - val_loss: 1.1615 - val_accuracy: 0.5806\n",
      "Epoch 8/30\n",
      "3304/3304 [==============================] - 73s 22ms/step - loss: 0.7875 - accuracy: 0.7192 - val_loss: 1.0886 - val_accuracy: 0.6161\n",
      "Epoch 9/30\n",
      "3304/3304 [==============================] - 73s 22ms/step - loss: 0.6513 - accuracy: 0.7716 - val_loss: 1.0473 - val_accuracy: 0.6449\n",
      "Epoch 10/30\n",
      "3304/3304 [==============================] - 73s 22ms/step - loss: 0.5476 - accuracy: 0.8121 - val_loss: 1.0032 - val_accuracy: 0.6701\n",
      "Epoch 11/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.4639 - accuracy: 0.8434 - val_loss: 0.9870 - val_accuracy: 0.6912\n",
      "Epoch 12/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.4012 - accuracy: 0.8664 - val_loss: 0.9692 - val_accuracy: 0.7032\n",
      "Epoch 13/30\n",
      "3304/3304 [==============================] - 73s 22ms/step - loss: 0.3493 - accuracy: 0.8856 - val_loss: 0.9159 - val_accuracy: 0.7257\n",
      "Epoch 14/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.3078 - accuracy: 0.8995 - val_loss: 0.9153 - val_accuracy: 0.7320\n",
      "Epoch 15/30\n",
      "3304/3304 [==============================] - 73s 22ms/step - loss: 0.2766 - accuracy: 0.9112 - val_loss: 0.8804 - val_accuracy: 0.7451\n",
      "Epoch 16/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.2472 - accuracy: 0.9202 - val_loss: 0.8719 - val_accuracy: 0.7545\n",
      "Epoch 17/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.2287 - accuracy: 0.9272 - val_loss: 0.8785 - val_accuracy: 0.7587\n",
      "Epoch 18/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.2064 - accuracy: 0.9350 - val_loss: 0.8568 - val_accuracy: 0.7705\n",
      "Epoch 19/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.1949 - accuracy: 0.9385 - val_loss: 0.8727 - val_accuracy: 0.7677\n",
      "Epoch 20/30\n",
      "3304/3304 [==============================] - 73s 22ms/step - loss: 0.1794 - accuracy: 0.9441 - val_loss: 0.8535 - val_accuracy: 0.7792\n",
      "Epoch 21/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.1685 - accuracy: 0.9471 - val_loss: 0.8718 - val_accuracy: 0.7780\n",
      "Epoch 22/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.1559 - accuracy: 0.9505 - val_loss: 0.8148 - val_accuracy: 0.7888\n",
      "Epoch 23/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.1475 - accuracy: 0.9540 - val_loss: 0.8232 - val_accuracy: 0.7923\n",
      "Epoch 24/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.1401 - accuracy: 0.9565 - val_loss: 0.8097 - val_accuracy: 0.7966\n",
      "Epoch 25/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.1326 - accuracy: 0.9589 - val_loss: 0.8534 - val_accuracy: 0.7908\n",
      "Epoch 26/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.1265 - accuracy: 0.9606 - val_loss: 0.8204 - val_accuracy: 0.8003\n",
      "Epoch 27/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.1201 - accuracy: 0.9631 - val_loss: 0.7940 - val_accuracy: 0.8046\n",
      "Epoch 28/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.1141 - accuracy: 0.9642 - val_loss: 0.7837 - val_accuracy: 0.8106\n",
      "Epoch 29/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.1084 - accuracy: 0.9664 - val_loss: 0.8024 - val_accuracy: 0.8082\n",
      "Epoch 30/30\n",
      "3304/3304 [==============================] - 72s 22ms/step - loss: 0.1046 - accuracy: 0.9675 - val_loss: 0.7904 - val_accuracy: 0.8120\n",
      "Training on class [1, 2, 3, 4, 5, 6, 7]  finished in  2175.513364315033 s\n",
      "Evaluate on class [1, 2, 3, 4, 5, 6, 7]\n",
      "1033/1033 [==============================] - 7s 7ms/step - loss: 0.7751 - accuracy: 0.8140\n",
      "0.8140231966972351\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "checkpoint = ModelCheckpoint(\"CascadeModel_S8_C1to7_Epochs50_test.h5\", monitor='val_accuracy', verbose=0, \n",
    "                             save_best_only=True, save_weights_only=False, mode='auto', save_freq='epoch')\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
    "\n",
    "model = get_compiled_casc_model(S, K=7)\n",
    "model.save('CascadeModel_S8_C1to7_init.h5')\n",
    "t1 = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size, \n",
    "                    verbose=1, validation_split=0.2, callbacks=[checkpoint,early])\n",
    "print('Training on class', classes, ' finished in ', str(time.time() - t1), 's')\n",
    "\n",
    "print('Evaluate on class', classes)\n",
    "\n",
    "# evaluate model\n",
    "_, accuracy = model.evaluate(X_test, y_test, batch_size=batch_size, verbose=1)\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, epochs=n_epochs, batch_size=batch_size, \n",
    "                    verbose=1, validation_split=0.2, callbacks=[checkpoint,early])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "nn_colab.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
